# 项目总结

## 最终成果

✅ **准确率: 0.93** (从初始的0.89提升到0.93)

## 技术路线

### 阶段1: 基础模型 (0.89-0.90)

**方法**: Triplet Loss + KNN 度量学习
- Backbone: ConvNeXt Large + ViT Large
- 分辨率: 448x448
- 数据增强: 翻转、旋转、颜色扰动
- TTA: 4视角测试增强

**结果**: 0.90

### 阶段2: 改进训练策略 (0.92)

**优化点**:
- 调整差分学习率 (adapter 1e-3, backbone 5e-6)
- 增加训练轮数 (25 epochs)
- 优化数据增强策略
- Auto-K搜索最佳邻居数

**结果**: 0.92

### 阶段3: 集成学习 (0.93)

**策略**: 双模型软投票
- Model 1: 0.90 (ConvNeXt + ViT @ 448)
- Model 2: 0.92 (改进版)
- 投票方式: 按准确率加权平均

**结果**: 0.93 ✅

## 失败的尝试

### 1. 不同Backbone组合

❌ **Swin + EfficientNetV2**: 0.74-0.79
- 原因: 这个组合在该数据集上效果不好
- 教训: 不是所有强力模型组合都有效

❌ **ConvNeXtV2 + BEiT**: 0.71
- 原因: 模型太大，显存不足，只能用384分辨率
- 教训: 硬件限制会影响模型选择

### 2. 多模型投票

❌ **加入0.82的模型**: 没有提升
- 原因: 准确率差距太大，预测差异是噪声而非互补
- 教训: 只有高准确率模型才值得集成

❌ **加入0.89的模型**: 没有提升
- 原因: 在关键争议样本上没有独特见解
- 教训: 模型间要有真正的互补性

### 3. 传统分类方法

❌ **CrossEntropy直接分类**: 0.57
- 原因: 小样本医学图像不适合直接分类
- 教训: 度量学习更适合小样本场景

## 关键经验

### ✅ 有效的方法

1. **度量学习优于直接分类**
   - Triplet Loss学习的特征更有区分性
   - KNN可以利用全部训练数据
   - 适合小样本医学图像

2. **高分辨率很重要**
   - 448比384效果明显更好
   - 医学图像细节决定诊断准确性

3. **ConvNeXt + ViT 是最优组合**
   - CNN和Transformer互补
   - 预训练权重质量高

4. **差分学习率是关键**
   - Adapter用大学习率快速适应
   - Backbone用小学习率保留预训练知识

5. **简单投票就够了**
   - 两个高准确率模型投票即可
   - 不需要复杂的stacking或blending

### ❌ 无效的方法

1. **盲目增加模型数量**
   - 低准确率模型会拖后腿
   - 模型间要有真正的差异性

2. **过度复杂的集成策略**
   - Stacking、Blending没有带来提升
   - 简单的加权平均就很好

3. **忽视硬件限制**
   - 显存不足导致只能用低分辨率
   - 影响最终效果

## 数据分析

### 模型一致性

- 0.90 vs 0.92: 96.4% 一致
- 0.89 vs 0.92: 94.4% 一致
- 0.82 vs 0.92: 94.0% 一致

### 争议样本

- 0.90和0.92有争议的样本: 9个 (3.6%)
- 其他模型在这些样本上没有独特见解
- 说明高准确率模型已经很稳定

## 技术栈

- **深度学习框架**: PyTorch
- **预训练模型**: timm (ConvNeXt, ViT)
- **度量学习**: Triplet Loss
- **分类器**: KNN (scikit-learn)
- **数据处理**: OpenCV, torchvision

## 计算资源

- **GPU**: CUDA (24GB显存)
- **训练时间**: 约2-3小时/模型
- **Batch Size**: 16-20
- **图像分辨率**: 448x448

## 可复现性

所有实验都设置了随机种子:
```python
seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
torch.backends.cudnn.deterministic = True
```

## 未来改进方向

1. **更大的模型**: 如果有更多显存，可以尝试更大的ViT
2. **更多数据**: 数据增强或外部数据集
3. **半监督学习**: 利用未标注数据
4. **注意力可视化**: 理解模型关注的区域
5. **模型蒸馏**: 压缩模型用于部署

## 项目文件

### 核心代码
- `ensemble_learning/metric_ensemble.py` - 度量学习训练 (0.92)
- `ensemble_learning/vote_ensemble.py` - 双模型投票 (0.93)
- `best_0.90/train_robust_pro.py` - 基础模型 (0.90)

### 工具脚本
- `ensemble_learning/analyze_predictions.py` - 预测分析

### 文档
- `README.md` - 项目说明
- `USAGE.md` - 使用指南
- `SUMMARY.md` - 本文件

### 模型权重
- `best_0.90/robust_pro_model.pth` - 0.90模型
- `ensemble_learning/metric_checkpoints/best_metric_ensemble.pth` - 0.92模型

### 预测结果
- `ensemble_learning/0.93.csv` - 最终预测 ✅

## 致谢

- timm库提供的预训练模型
- PyTorch深度学习框架
- scikit-learn机器学习工具

---

**项目完成时间**: 2025年1月
**最终准确率**: 0.93
**提升幅度**: +4.5% (从0.89到0.93)
